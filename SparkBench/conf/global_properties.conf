# Sparkbench properties
# CPU cores per node * number of nodes, i.e. sum of all cpu cores in your cluster,
#   use taskScheduler.defaultParallelism as default if not specified
spark.default.parallelism     256

# Reducer number for terasort, default to spark.default.parallelism / 2 if not specified
sparkbench.reducer            128

# Available formats: Text, Sequence. Defaults: Text
# Specifiy Compress codec, None -> no compress. Defaults: None
sparkbench.inputformat        Sequence
sparkbench.inputformat.codec  None 
#sparkbench.intputformat.codec  org.apache.hadoop.io.compress.SnappyCodec

sparkbench.outputformat       Sequence
sparkbench.outputformat.codec  None
#sparkbench.outputformat.codec  org.apache.hadoop.io.compress.SnappyCodec

# Compression
spark.rdd.compress            false
# compression codec: lz4, lzf, snappy, put class path here accordingly.
spark.io.compression.codec    org.apache.spark.io.SnappyCompressionCodec 

# Akka
spark.akka.frameSize          1000
spark.akka.timeout            600

# port binding
spark.driver.port             9500
spark.fileserver.port         9501
spark.broadcast.port          9502
spark.replClassServer.port    9503
spark.blockManager.port       9504
spark.executor.port           9505

# mllib will use KyroSerializer, ensure the buffer is large enough
spark.kryoserializer.buffer.mb  2000
