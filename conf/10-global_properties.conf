# Hibench properties
hibench.hadoop.home		/home/lv/intel/hadoop/hadoop-1.2.1
hibench.spark.home		/home/lv/intel/spark-1.2.1-bin-hadoop1
hibench.hdfs.master		hdfs://localhost:54310
hibench.spark.master		spark://helix2:7077
hibench.default.map.parallelism		2
hibench.default.shuffle.parallelism	2

# Sparkbench properties
# CPU cores per node * number of nodes, i.e. sum of all cpu cores in your cluster,
#   use taskScheduler.defaultParallelism as default if not specified
spark.default.parallelism     ${hibench.default.map.parallelism}

# Reducer number for terasort, default to spark.default.parallelism / 2 if not specified
# sparkbench.reducer            ${hibench.default.shuffle.parallelism}

# Available formats: Text, Sequence. Defaults: Text
# Specifiy Compress codec, None -> no compress. Defaults: None
sparkbench.inputformat        Sequence
sparkbench.inputformat.codec  None 
#sparkbench.intputformat.codec  org.apache.hadoop.io.compress.SnappyCodec

sparkbench.outputformat       Sequence
sparkbench.outputformat.codec  None
#sparkbench.outputformat.codec  org.apache.hadoop.io.compress.SnappyCodec

# Compression
spark.rdd.compress            false
# compression codec: lz4, lzf, snappy, put class path here accordingly.
spark.io.compression.codec    org.apache.spark.io.SnappyCompressionCodec 

# Akka
spark.akka.frameSize          1000
spark.akka.timeout            600

# port binding
#spark.driver.port             9500
#spark.fileserver.port         9501
#spark.broadcast.port          9502
#spark.replClassServer.port    9503
#spark.blockManager.port       9504
#spark.executor.port           9505

# mllib will use KyroSerializer, ensure the buffer is large enough
spark.kryoserializer.buffer.mb	 2000
