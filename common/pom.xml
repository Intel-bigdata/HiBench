<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <artifactId>sparkbench</artifactId>
    <packaging>jar</packaging>
    <groupId>com.intel.sparkbench</groupId>
    <version>1.0</version>
    <name>Sparkbench</name>
    <url>https://github.com/Intel-bigdata/Sparkbench</url>

    <properties>
      <maven.compiler.source>1.6</maven.compiler.source>
      <maven.compiler.target>1.6</maven.compiler.target>
      <encoding>UTF-8</encoding>
      <scala.version>2.10.4</scala.version>
      <scala.binary.version>2.10</scala.binary.version>
      <spark.version>1.3.0</spark.version>
      <spark.bin.version>1.3</spark.bin.version>
      <sparkbench.mr.version>MR2</sparkbench.mr.version>
    </properties>

    <dependencies>
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
            <version>${scala.version}</version>
        </dependency>
        <dependency>
            <groupId>junit</groupId>
            <artifactId>junit</artifactId>
            <version>3.8.1</version>
            <scope>test</scope>
        </dependency>

        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_${scala.binary.version}</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming_${scala.binary.version}</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-mllib_${scala.binary.version}</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-hive_${scala.binary.version}</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-graphx_${scala.binary.version}</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>com.github.scopt</groupId>
            <artifactId>scopt_2.10</artifactId>
            <version>3.2.0</version>
        </dependency>
        <dependency>
            <groupId>org.apache.mahout</groupId>
            <artifactId>mahout-core</artifactId>
            <version>0.9</version>
        </dependency>
        <dependency>
            <groupId>org.apache.mahout</groupId>
            <artifactId>mahout-math</artifactId>
            <version>0.9</version>
        </dependency>
      <dependency>
        <groupId>log4j</groupId>
        <artifactId>log4j</artifactId>
        <version>1.2.17</version>
        <scope>compile</scope>
        </dependency>
     </dependencies>
    <build>
 
      <plugins>
	<plugin>
	  <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-compiler-plugin</artifactId>
            <configuration>
	      <directory>com/intel/sparkbench/mulit_api</directory>
	      <includes>
		<include>com/intel/sparkbench/multi_api/spark${spark.bin.version}/*.java</include>
		<include>com/intel/sparkbench/multi_api/${sparkbench.mr.version}/*.java</include>
	      </includes>
	    </configuration>
        </plugin>
	<plugin>
	  <groupId>net.alchim31.maven</groupId>
	  <artifactId>scala-maven-plugin</artifactId>	 
	  <executions>
	    <execution>
	      <id>scala-compile-first</id>
	      <phase>process-resources</phase>
	      <configuration>
	      <excludes>
		<exclude>**/*.java</exclude>
		<exclude>com/intel/sparkbench/multi_api/MR1/</exclude>
	      </excludes>
	    </configuration>
	      <goals>
		<goal>add-source</goal>
		<goal>compile</goal>
	      </goals>
	    </execution>
	    <execution>
	      <id>scala-test-compile</id>
	      <phase>process-test-resources</phase>
	      <goals>
		<goal>testCompile</goal>
	      </goals>
	    </execution>
	  </executions>
	</plugin>
	<plugin>
	  <artifactId>maven-assembly-plugin</artifactId>
	  <version>2.5.3</version>
	  <configuration>
	    <descriptorRefs>
	      <descriptorRef>jar-with-dependencies</descriptorRef>
	    </descriptorRefs>
	  </configuration>
	  <executions>
	    <execution>
	      <id>make-assembly</id>
	      <phase>package</phase>
	      <goals>
		<goal>single</goal>
	      </goals>
	    </execution>
	  </executions>
	</plugin>
      </plugins>

      <pluginManagement>
	<plugins>
	  <plugin>
	    <groupId>org.apache.maven.plugins</groupId>
	    <artifactId>maven-compiler-plugin</artifactId>
	    <version>3.2</version>
	  </plugin>
	  <plugin>
	    <groupId>net.alchim31.maven</groupId>
	    <artifactId>scala-maven-plugin</artifactId>
	    <version>3.2.0</version>
	    <configuration>
	      <scalaCompatVersion>${scala.binary.version}</scalaCompatVersion>
	      <scalaVersion>${scala.version}</scalaVersion>
	    </configuration>
	  </plugin>
	  
	</plugins>
      </pluginManagement>
    </build>
    

    <repositories>
      <repository>
	<id>central</id>
	<!-- This should be at top, it makes maven try the central repo first and then others and hence faster dep resolution -->
	<name>Maven Repository</name>
	<url>https://repo1.maven.org/maven2</url>
	<releases>
	  <enabled>true</enabled>
	</releases>
	<snapshots>
	  <enabled>false</enabled>
	</snapshots>
      </repository>
      <repository>
	<id>apache-repo</id>
	<name>Apache Repository</name>
	<url>https://repository.apache.org/content/repositories/releases</url>
	<releases>
	  <enabled>true</enabled>
	</releases>
	<snapshots>
	  <enabled>false</enabled>
	</snapshots>
      </repository>
      
      <repository>
	<id>scala-tools.org</id>
	<name>Scala-tools Maven 2 Repository</name>
	<url>https://oss.sonatype.org/content/groups/scala-tools/</url>
      </repository>
    </repositories>
    <pluginRepositories>
      <pluginRepository>
	<id>scala-tools.org</id>
	<name>Scala-tools Maven2 Repository</name>
	<url>https://oss.sonatype.org/content/groups/scala-tools/</url>
      </pluginRepository>
    </pluginRepositories>

    <profiles>
      <profile>
	<id>hadoop1</id>
	<build>
	  <plugins>
	    <plugin>
	      <groupId>net.alchim31.maven</groupId>
	      <artifactId>scala-maven-plugin</artifactId>	 
	      <configuration>
		<excludes>
		  <exclude>com/intel/sparkbench/multi_api/MR2/</exclude>
		</excludes>
	      </configuration>
	    </plugin>
	  </plugins>
	</build>
	<properties>
	  <sparkbench.mr.version>MR1</sparkbench.mr.version>
	</properties>
	<activation>
	  <property><name>hadoop1</name></property>
        </activation>
      </profile>

      <profile>
	<id>hadoop2</id>
	<build>
	  <plugins>
	    <plugin>
	      <groupId>net.alchim31.maven</groupId>
	      <artifactId>scala-maven-plugin</artifactId>	 
	      <configuration>
		<excludes>
		  <exclude>com/intel/sparkbench/multi_api/MR1/</exclude>
		</excludes>
	      </configuration>
	    </plugin>
	  </plugins>
	</build>
	<properties>
	  <sparkbench.mr.version>MR2</sparkbench.mr.version>
	</properties>
	<dependencies>
	  <dependency>
	    <groupId>org.apache.hadoop</groupId>
	    <artifactId>hadoop-mapreduce-examples</artifactId>
	    <version>2.2.0</version>
	  </dependency>
	</dependencies>
	<activation>
	  <property><name>!hadoop1</name></property>
        </activation>
      </profile>
      
      <profile>
	<id>spark1.2</id>
	<properties>
 	  <spark.version>1.2.0</spark.version>
	  <spark.bin.version>1.2</spark.bin.version>
	</properties>
	<activation>
	  <property><name>spark1.2</name></property>
	</activation>
      </profile>
      
      <profile>
	<id>spark1.3</id>
	<properties>
	  <env>spark1.3</env>
	  <spark.version>1.3.0</spark.version>
	  <spark.bin.version>1.3</spark.bin.version>
	</properties>
	<activation>
	  <property><name>!spark1.2</name></property>
	</activation>
      </profile>
    </profiles>
</project>

